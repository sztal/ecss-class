{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web APIs and HTTP requests: part II\n",
    "\n",
    "Brief reminder. Web API (*Application Programming Interface*) is a web-based (often public or semi-public), a programmable interface that allows third parties to communicate with some digital system in an organized and automated manner.\n",
    "\n",
    "More importantly, the majority of web APIs use the HTTP protocol to communicate with the external world. The HTTP protocol is the standard communication protocol used everywhere around the World Wide Web (this is exactly the protocol that your browser uses to communicate with servers that host websites you use). By this virtue REST API are very universal and flexible as HTTP-based communication is supported by every serious programming language and/or operating system. Moreover, it makes it even possible to use REST APIs via a browser, which is very handy for testing.\n",
    "\n",
    "So, in summary, a web API is:\n",
    "\n",
    "* **Remote.** Users can access the resources from anywhere, provided they have an internet connection.\n",
    "* **Reliable.** The interface exposed to users is stable, which means that it does not change often in time and is largely independent of changes within the system on top of which it sits.\n",
    "* **Programmable.** API can be interacted with based on a predefined set of commands/methods/endpoints (an interface) in a way that can be expressed with a programming language.\n",
    "\n",
    "Moreover, perhaps one of the most important features of a web API is the fact that it is identified by a unique URL and IP number (exactly in the same way as any ordinary website). Every particular method/endpoint in the API can be interacted with by extending the base URL of the API with appropriate query parameters and/or subdirectories. For example:\n",
    "\n",
    "* https://en.wikipedia.org/w/api.php is the base URL of the Wikipedia API.\n",
    "* https://en.wikipedia.org/w/api.php?action=query&list=random&rnnamespace=0&rnlimit=2 is the URL that uses the `query` endpoint and the `list` method nested within it.\n",
    "\n",
    "Let us remind ourselves of the anatomy of URL-based communication with web APIs.\n",
    "\n",
    "The base URL `https://en.wikipedia.org/w/api.php` is a simple, standard URL. Nothing special about except for the fact that it points to the location at which the Wikipedia API lives. Now, note that the `query` action is an extension of the base URL of the following form:\n",
    "\n",
    "* `<BASE_URL> ? <QUERY STRING>`\n",
    "* Where query string is a sequence of key-value pairs of the following form `<key1>=<value1>&<key2>=<value2> ...`.\n",
    "\n",
    "The `?` sign separates the base URL from the query string part. And in our example, the query params (key-value pairs) specify that we want the API to use the `query` endpoint and use it to execute the `list=random` method with the following arguments: `rnamespace=0&rnlimit=2`. The `query` endpoint and all its methods such as `list=random` are properly documented at: `https://en.wikipedia.org/w/api.php?action=help&modules=query` (note that this website is served also through an API query)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Wikipedia API: part II\n",
    "\n",
    "The last time we extracted the list of Wikiprojects and counted them. This time we will try to do something a little bit more involved.\n",
    "\n",
    "1. We gonna take a random sample of 10 Wikipedia articles. There is an endpoint in the Wikipedia for doing just that. However, note because of the sampling each of you will get different results.\n",
    "2. The first step will give us only id numbers and the title of the pages. We will use them to extract the full text of the pages via a different endpoint of the Wikipedia API.\n",
    "3. We will compute word length distributions of the pages. Exactly, we will reuse the code that you developed earlier for the final exercise from notebook 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.\n",
    "\n",
    "First, we have to sample 10 random Wikipedia articles. This should not be too hard since we have a special method for this, so it should be just one simple API call.\n",
    "\n",
    "The method we are looking for is `list=random` and it is defined within the `query` endpoint (`action=query`). We can read more about it [here](https://en.wikipedia.org/w/api.php?action=help&modules=query%2Brandom).\n",
    "\n",
    "**HINT.** Remember that you can view the results of your queries directly in the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick read of the doc page and we can decide that we need only two query parameters:\n",
    "\n",
    "1. `rnamespace=0` (which limits the results to the namespace `0` which is the part of Wikipedia where actual encyclopedic articles live).\n",
    "2. `rnlimit=10` (because we want to extract only 10 random articles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above considerations lead us to the following payload\n",
    "# we will want to attach to out query URL.\n",
    "\n",
    "payload = {\n",
    "    'action': 'query',  # since we want to use the `query` endpoint\n",
    "    'list': 'random',   # because we want to use the `random` method\n",
    "    # But we also need to add arguments for the `random` method\n",
    "    'rnnamespace': 0,\n",
    "    'rnlimit': 10,\n",
    "    'format': 'json'    # we need to add it so the data can be read by Python\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to make the GET request\n",
    "# But first we need to import the requests package\n",
    "import requests as rq\n",
    "# And define our base URL\n",
    "BASE_URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "response = rq.get(BASE_URL, params=payload)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that our response is OK (HTTP response code 200 means 'OK')\n",
    "# So we can extract the data from the response object with `.json()`\n",
    "# method defined on it.\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now we have titles of articles and their unique ids. As you can probably imagine we are only interested in the unique ids at this point. Because we will need them to in different endpoint to extract texts of the articles. But how exactly we are going to access them? It is a dictionary so it should not be a major problem to access a single value, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['query']['random'][0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what exactly happened there? First, we got a mapping with three keys: `batchcomplete`, `continue`, and `query`. We were only interested in the `query` field. Therefore, we typed as follows:\n",
    "```python\n",
    "data['query']\n",
    "```\n",
    "However, it was again a mapping inside a mapping with only one field: `random`. Therefore:\n",
    "```python\n",
    "data['query']['random']\n",
    "```\n",
    "Inside this mapping, we had a five-element list. So to access the first element we typed:\n",
    "```python\n",
    "data['query']['random'][0]\n",
    "```\n",
    "Every element of that list was also a mapping again with three keys: `id`, `ns`, and `title`. We were only interested in the `id` field. So, we just typed:\n",
    "```python\n",
    "data['query']['random'][0]['id']\n",
    "```\n",
    "However, again we could access all the `ids` manually but it would be easier just to use a for-loop. As you probably can imagine we are going to loop over that list because the rest of the fields are going to be the same.\n",
    "\n",
    "```python\n",
    "for page in data['query']['random']:\n",
    "    print(page['id'])\n",
    "```\n",
    "So a loop like this would work fine if we only wanted to print the `ids`. We could even modify it a bit to store the `ids` in the list (it is what we want to do), for example:\n",
    "```python\n",
    "list_ids = []\n",
    "for page in data['query']['random']:\n",
    "    list_ids.append(page['id'])\n",
    "```\n",
    "So first, we would create a list outside of the loop and then use a method `append` to add each value of `page['id']` as the last element of the list. It is doable. But Python offers a smarter way of saving results of the loop in a list. It is called **list comprehension** and in this particular example looks like this:\n",
    "```python\n",
    "page_ids = [ page['id'] for page in data['query']['random'] ]\n",
    "```\n",
    "It does exactly the same as the previous example but in a neater way. The difference is that first you write what is happening in the loop `page['id']` and afterward you define the loop `for page in data['query']['random']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the obtained relatively simply dictionary\n",
    "# We can extract the list of page ids as follows:\n",
    "page_ids = [ page['id'] for page in data['query']['random'] ]\n",
    "page_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.\n",
    "Now we have a nice list of page ids, so we can use it to extract the content of the pages using a different method defined on the `query` endpoint.\n",
    "\n",
    "We will use a so-called _cirrus doc_ endpoint. _Cirrus_ is a system for organizing and storing text documents used by Wikipedia. It does not really matter to us. What matters is the fact that an endpoint like this exists and that it has a particular format.\n",
    "\n",
    "As we said _cirrus doc_ is a method on the `query` endpoint and we can call it with `prop=cirrusdoc`. However, to obtain any data we have also to pass a list of page ids in a proper format.\n",
    "\n",
    "Remember every piece of data that we provide through URL parameters (query string) is always treated as a string. Thanks to this every API can use some convention for defining lists of values. The Wikipedia API uses `|` as the separator, so it uses the following convention:\n",
    "\n",
    "* `<item 1>|<item 2>| ... |<item n>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus we have to join our page ids to form a single string\n",
    "page_ids_string = \"|\".join(str(p) for p in page_ids) ## this for loop is written similarly as the previous one\n",
    "page_ids_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the above considerations already enforce a particular form of a payload\n",
    "# that we will have to attach to the request URL.\n",
    "\n",
    "payload = {\n",
    "    'action': 'query',\n",
    "    'prop': 'cirrusdoc',\n",
    "    'pageids': page_ids_string,\n",
    "    'format': 'json'\n",
    "}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we are ready to make a request\n",
    "response = rq.get(BASE_URL, params=payload)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And parse the response to a json dictionary\n",
    "data = response.json()\n",
    "# We can look and the top-level keys of the dict\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should be interested in the query field, since judging by the name\n",
    "# it should contain the results of our query\n",
    "data['query'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, now we have only one key on the lower level, so it has to store the data\n",
    "pages = data['query']['pages']\n",
    "pages.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that the pages dictionary store all the pages we requested identified with their ids\n",
    "# Let us look at the inner keys of sub-dict with data of a single page\n",
    "key = list(pages)[0]\n",
    "pages[key].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems that the main data is stored under the `cirrusdoc` key.\n",
    "type(pages[key]['cirrusdoc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm, the cirrusdoc property is a list.\n",
    "# So we have to extract data from it.\n",
    "pages[key]['cirrusdoc'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, finally we see the source key, that must store the actual article content\n",
    "pages[key]['cirrusdoc'][0]['source'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bingo!! We see the `text` field. It contains the article text.\n",
    "# This is exactly what we want to extract.\n",
    "pages[key]['cirrusdoc'][0]['source']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examined the anatomy of the response of the _cirrus doc_ method in the Wikipedia API. So now we understand it and we can use this new knowledge to automatically extract the content of all the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [ p['cirrusdoc'][0]['source']['text'] for p in pages.values() ]\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE THAT THE PREVIOUS EXPRESSION\n",
    "## DOES THE SAME AS THE FOLLOWING MORE VERBOSE EXPRESSION\n",
    "articles = []\n",
    "for page_id in pages.keys():\n",
    "  page = pages[page_id]\n",
    "  cirrus = page['cirrusdoc']\n",
    "  page_data = cirrus[0]\n",
    "  source = page_data['source']\n",
    "  text = source['text']\n",
    "  articles.append(text)\n",
    "\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!!! We finally extracted the data we want. Now we can apply our method for computing word length distributions to this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework (deadline: 11.12.2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write solutions for the homework exercises in this notebook. Once the work is done download the notebook file (`File > Download .ipynb`) rename it properly so it follows a template `HW1_<NAME>_<SURNAME>.ipynb` and send the file to us. Use one (or preferably both) of the following e-mails:\n",
    "\n",
    "* <stalaga@uw.edu.pl>\n",
    "* <m.biesaga@uw.edu.pl>\n",
    "\n",
    "Remember that you can contact us if you have any problems. You can describe your problems in the `hw1` channel or in private messages to us on Slack. You can also write normal e-mails. Moreover, you can also visit us in the ISS on the fourth floor (room 415). Usually, at least one of us is there after 11/12 for at least a few hours. Although it is best to set up a meeting earlier via e-mail or a private message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1 | Exercise 1.\n",
    "\n",
    "Read about the `pageviews` method (`prop=pageviews`) in the `query endpoint` ([docpage](https://en.wikipedia.org/w/api.php?action=help&modules=query%2Bpageviews)). Use this method to extract page views data for the pages from the previous exercise (if you want you can sample 10 new pages with the `list=random` method) for the last 60 days.\n",
    "\n",
    "The results will be broken down by single days, so you have to aggregate the results (sum) so they give the total page views count for the entire period of 60 days.\n",
    "\n",
    "Remember that to select pages by page ids you pass `pageids=<id 1>|<id 2>|...|<id n>`. We did a very similar thing when we extracted article content through the `cirrusdoc` method in the Wikipedia API in the previous part of this notebook.\n",
    "\n",
    "Your final output should be a `dict` object that maps page ids to pageviews (total number of pageviews over 60 days). It should look something like this:\n",
    "\n",
    "```python\n",
    "results = {\n",
    "    # page_id: pageviews\n",
    "    153253: 10204,\n",
    "    423423: 101,\n",
    "    11012:  12,\n",
    "    42435:  546,\n",
    "    # and so on\n",
    "}\n",
    "```\n",
    "\n",
    "If you want you can sample 10 pages yourself. Otherwise, you may use the following list of page ids that we prepared for you.\n",
    "Sampling pages yourself will give you extra credit (but it is possible to get maximum points without it as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "page_ids = [\n",
    "    19969580,\n",
    "    39982842,\n",
    "    25699035,\n",
    "    52642931,\n",
    "    53055349,\n",
    "    24133565,\n",
    "    1164662,\n",
    "    40656459,\n",
    "    12533026,\n",
    "    47110862\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_URL = 'https://en.wikipedia.org/w/api.php'\n",
    "\n",
    "params = {\n",
    "    'action': 'query',\n",
    "    'prop': 'pageviews',\n",
    "    'pageids': '|'.join(str(pid) for pid in page_ids),\n",
    "    'pvidays': 60,\n",
    "    'format': 'json'\n",
    "}\n",
    "response = requests.get(BASE_URL, params=params)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1164662: 1697,\n",
       " 12533026: 845,\n",
       " 19969580: 407,\n",
       " 24133565: 2103,\n",
       " 25699035: 54,\n",
       " 39982842: 28,\n",
       " 40656459: 20,\n",
       " 47110862: 60,\n",
       " 52642931: 18,\n",
       " 53055349: 89}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = response.json()['query']['pages']\n",
    "PV = { int(k): sum(filter(None, v.get('pageviews', {}).values())) for k, v in data.items() }\n",
    "PV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 1 | Exercise 2.\n",
    "\n",
    "(this is a pure Python exercise for practice; not related to web APIs)\n",
    "\n",
    "Write a function that takes one argument `n` and prints a simple pyramid of the following form:\n",
    "\n",
    "$n = 3$\n",
    "```\n",
    "  *\n",
    " ***\n",
    "*****\n",
    "```\n",
    "\n",
    "$n = 5$\n",
    "```\n",
    "    *\n",
    "   ***\n",
    "  *****\n",
    " *******\n",
    "*********\n",
    "```\n",
    "\n",
    "Remember that we define a function in Python like this.\n",
    "\n",
    "```python\n",
    "def add_two_numbers(x, y):\n",
    "    return x + y\n",
    "```\n",
    "\n",
    "And that you can print from functions like this.\n",
    "\n",
    "```python\n",
    "def print_a_string_from_function(string):\n",
    "    print(string)\n",
    "```\n",
    "\n",
    "Note that to print something you do not use the `return` statement.\n",
    "\n",
    "HINT. You may want to use the fact that in Python strings can be easily multiplied.\n",
    "For instance:\n",
    "\n",
    "```python\n",
    "'x' * 5 == 'xxxxx'\n",
    "```\n",
    "\n",
    "Note that you can do the same with an ,,empty'' space.\n",
    "\n",
    "```python\n",
    "\" \" * 5 == \"     \"\n",
    "```\n",
    "\n",
    "HINT 2. It may be convenient to use a for loop for printing.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```python\n",
    "print_pyramid(4)\n",
    "```\n",
    "\n",
    "Should print:\n",
    "```\n",
    "   *\n",
    "  ***\n",
    " *****\n",
    "*******\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         *\n",
      "        ***\n",
      "       *****\n",
      "      *******\n",
      "     *********\n",
      "    ***********\n",
      "   *************\n",
      "  ***************\n",
      " *****************\n",
      "*******************\n"
     ]
    }
   ],
   "source": [
    "def print_pyramid(n):\n",
    "    print(\"\\n\".join(' '*(n-1-i) + '*'*(2*i + 1) for i in range(n)))\n",
    "\n",
    "print_pyramid(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
